{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::756783949033:role/service-role/AmazonSageMaker-ExecutionRole-20200307T170737\n",
      "CPU times: user 103 ms, sys: 12.4 ms, total: 115 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'objectdataset' # custom bucket name.\n",
    "# bucket = sess.default_bucket()\n",
    "prefix = 'DEMO-ObjectDetection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/object-detection:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "# MSCOCO validation image files\n",
    "download('http://images.cocodataset.org/zips/val2017.zip')\n",
    "download('http://images.cocodataset.org/annotations/annotations_trainval2017.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "unzip -qo val2017.zip\n",
    "unzip -qo annotations_trainval2017.zip\n",
    "rm val2017.zip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generated’: File exists\n",
      "mkdir: cannot create directory ‘train’: File exists\n",
      "mkdir: cannot create directory ‘train_annotation’: File exists\n",
      "mkdir: cannot create directory ‘validation’: File exists\n",
      "mkdir: cannot create directory ‘validation_annotation’: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Create folders to store the data and annotation files\n",
    "mkdir generated train train_annotation validation validation_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "def get_coco_mapper():\n",
    "    original_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                    21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
    "                    41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
    "                    61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
    "                    81, 82, 84, 85, 86, 87, 88, 89, 90]\n",
    "    iter_counter = 0\n",
    "    COCO = {}\n",
    "    for orig in original_list:\n",
    "        COCO[orig] = iter_counter\n",
    "        iter_counter += 1\n",
    "    return COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapper_fn(map):  \n",
    "    def mapper(in_category):\n",
    "        return map[in_category]\n",
    "    return mapper\n",
    "\n",
    "fix_index_mapping = get_mapper_fn(get_coco_mapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-baeb4620a4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                 })\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "file_name = './annotations/instances_val2017.json'\n",
    "with open(file_name) as f:\n",
    "    js = json.load(f)\n",
    "    images = js['images']\n",
    "    categories = js['categories']\n",
    "    annotations = js['annotations']\n",
    "    for i in images:\n",
    "        jsonFile = i['file_name']\n",
    "        jsonFile = jsonFile.split('.')[0]+'.json'\n",
    "        \n",
    "        line = {}\n",
    "        line['file'] = i['file_name']\n",
    "        line['image_size'] = [{\n",
    "            'width':int(i['width']),\n",
    "            'height':int(i['height']),\n",
    "            'depth':3\n",
    "        }]\n",
    "        line['annotations'] = []\n",
    "        line['categories'] = []\n",
    "        for j in annotations:\n",
    "            if j['image_id'] == i['id'] and len(j['bbox']) > 0:\n",
    "                line['annotations'].append({\n",
    "                    'class_id':int(fix_index_mapping(j['category_id'])),\n",
    "                    'top':int(j['bbox'][1]),\n",
    "                    'left':int(j['bbox'][0]),\n",
    "                    'width':int(j['bbox'][2]),\n",
    "                    'height':int(j['bbox'][3])\n",
    "                })\n",
    "                class_name = ''\n",
    "                for k in categories:\n",
    "                    if int(j['category_id']) == k['id']:\n",
    "                        class_name = str(k['name'])\n",
    "                assert class_name is not ''\n",
    "                line['categories'].append({\n",
    "                    'class_id':int(j['category_id']),\n",
    "                    'name':class_name\n",
    "                })\n",
    "        if line['annotations']:\n",
    "            with open(os.path.join('generated', jsonFile),'w') as p:\n",
    "                json.dump(line,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4952 images have annotation files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "jsons = os.listdir('generated')\n",
    "\n",
    "print ('There are {} images have annotation files'.format(len(jsons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Destination path './train/000000137294.jpg' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-165be9fa5d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_jsons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./val2017/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./generated/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./train_annotation/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mreal_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Destination path './train/000000137294.jpg' already exists"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "train_jsons = jsons[:4452]\n",
    "val_jsons = jsons[4452:]\n",
    "\n",
    "#Moving training files to the training folders\n",
    "for i in train_jsons:\n",
    "    image_file = './val2017/'+i.split('.')[0]+'.jpg'\n",
    "    shutil.move(image_file, './train/')\n",
    "    shutil.move('./generated/'+i, './train_annotation/')\n",
    "\n",
    "#Moving validation files to the validation folders\n",
    "for i in val_jsons:\n",
    "    image_file = './val2017/'+i.split('.')[0]+'.jpg'\n",
    "    shutil.move(image_file, './validation/')\n",
    "    shutil.move('./generated/'+i, './validation_annotation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 5.01 s, total: 1min 7s\n",
      "Wall time: 12min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "\n",
    "sess.upload_data(path='train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='validation', bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path='train_annotation', bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(path='validation_annotation', bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode = 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=80,\n",
    "                             mini_batch_size=16,\n",
    "                             epochs=1,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step='10',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=600,\n",
    "                             num_training_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "train_annotation = sagemaker.session.s3_input(s3_train_annotation, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data,\n",
    "                 'train_annotation': train_annotation, 'validation_annotation':validation_annotation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-06 20:14:59 Starting - Starting the training job...\n",
      "2020-04-06 20:15:01 Starting - Launching requested ML instances......\n",
      "2020-04-06 20:16:09 Starting - Preparing the instances for training......\n",
      "2020-04-06 20:17:24 Downloading - Downloading input data............\n",
      "2020-04-06 20:19:23 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'30', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'32', u'use_pretrained_model': u'0', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'', u'base_network': u'vgg-16', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'epochs': u'1', u'nms_threshold': u'0.45', u'optimizer': u'sgd', u'base_network': u'resnet-50', u'image_shape': u'512', u'label_width': u'600', u'lr_scheduler_step': u'10', u'momentum': u'0.9', u'overlap_threshold': u'0.5', u'num_training_samples': u'500', u'mini_batch_size': u'16', u'weight_decay': u'0.0005', u'use_pretrained_model': u'1', u'num_classes': u'80', u'lr_scheduler_factor': u'0.1'}\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Final configuration: {u'label_width': u'600', u'early_stopping_min_epochs': u'10', u'epochs': u'1', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'16', u'use_pretrained_model': u'1', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'10', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'500', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'80', u'base_network': u'resnet-50', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'512'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:26 INFO 140162655606592] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:28 INFO 140162655606592] nvidia-smi took: 0.0252280235291 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34mCreating .rec file from /opt/ml/input/data/train/train.lst in /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mtime: 0.0332541465759  count: 0\u001b[0m\n",
      "\u001b[34mtime: 1.93656897545  count: 1000\u001b[0m\n",
      "\u001b[34mtime: 1.93285989761  count: 2000\u001b[0m\n",
      "\u001b[34mtime: 2.02364802361  count: 3000\u001b[0m\n",
      "\u001b[34mtime: 1.85089993477  count: 4000\u001b[0m\n",
      "\u001b[34mCreating .rec file from /opt/ml/input/data/validation/val.lst in /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mtime: 0.0816180706024  count: 0\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:43 INFO 140162655606592] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:43 WARNING 140162655606592] Training images are resized to image shape (3, 512, 512)\u001b[0m\n",
      "\u001b[34m[20:19:43] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[20:19:43] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, label padding width: 600\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:45 WARNING 140162655606592] Validation images are resized to image shape (3, 512, 512)\u001b[0m\n",
      "\u001b[34m[20:19:45] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[20:19:45] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, label padding width: 600\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Using [gpu(0)] as training context.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Using (gpu(0)) as training context.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Start training from pretrained model 1.\u001b[0m\n",
      "\u001b[34m[20:19:47] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[20:19:47] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:19:47 INFO 140162655606592] Loaded pretrained model parameters.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:20:01 INFO 140162655606592] Creating a new state instance.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1586204401.294501, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1586204401.29442}\n",
      "\u001b[0m\n",
      "\u001b[34m[20:20:02] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:20:44 INFO 140162655606592] Epoch:    0, batches:    100, num_examples:   1600, 37.4 samples/sec, epoch time so far:  0:00:42.819794\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:19 INFO 140162655606592] Epoch:    0, batches:    200, num_examples:   3200, 40.8 samples/sec, epoch time so far:  0:01:18.336838\u001b[0m\n",
      "\n",
      "2020-04-06 20:21:58 Uploading - Uploading generated training model\u001b[34m[04/06/2020 20:21:46 WARNING 140162655606592] Expected number of batches: 31, did not match the number of batches processed: 279. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:46 INFO 140162655606592] #quality_metric: host=algo-1, epoch=0, batch=279 train cross_entropy <loss>=(2.8537929095651835)\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:46 INFO 140162655606592] #quality_metric: host=algo-1, epoch=0, batch=279 train smooth_l1 <loss>=(0.9540906765304936)\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:46 INFO 140162655606592] Round of batches complete\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:46 INFO 140162655606592] Updated the metrics\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 INFO 140162655606592] #quality_metric: host=algo-1, epoch=0, validation mAP <score>=(0.0001666593562761897)\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 INFO 140162655606592] Updating the best model with validation-mAP=0.0001666593562761897\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 INFO 140162655606592] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 INFO 140162655606592] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1586204514.442489, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 0}, \"StartTime\": 1586204401.294774}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 WARNING 140162655606592] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 INFO 140162655606592] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[04/06/2020 20:21:54 INFO 140162655606592] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"totaltime\": {\"count\": 1, \"max\": 148929.39710617065, \"sum\": 148929.39710617065, \"min\": 148929.39710617065}, \"setuptime\": {\"count\": 1, \"max\": 11.853933334350586, \"sum\": 11.853933334350586, \"min\": 11.853933334350586}}, \"EndTime\": 1586204515.467058, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1586204366.627023}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-06 20:22:25 Completed - Training job completed\n",
      "Training seconds: 301\n",
      "Billable seconds: 301\n"
     ]
    }
   ],
   "source": [
    "\n",
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "object_detector = od_model.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!wget -O test.jpg https://images.pexels.com/photos/980382/pexels-photo-980382.jpeg\n",
    "\n",
    "file_name = 'test.jpeg'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "    ne = open('n.txt','wb')\n",
    "    ne.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[0.0, 0.26511406898498535, 0.7410074472427368, 0.5448190569877625, 0.7947453260421753, 0.640901505947113], [0.0, 0.24890373647212982, 0.7486700415611267, 0.513748049736023, 0.7930073142051697, 0.6037830114364624], [0.0, 0.23618142306804657, 0.4012477993965149, 0.28912079334259033, 0.8299674391746521, 0.9700943231582642], [0.0, 0.23428979516029358, 0.5273383855819702, 0.47358790040016174, 0.5713183879852295, 0.5758661031723022], [0.0, 0.22448909282684326, 0.07599130272865295, 0.3144729435443878, 0.6611346006393433, 0.9096550941467285], [0.0, 0.21315857768058777, 0.18743368983268738, 0.5091853141784668, 0.42540332674980164, 1.0], [0.0, 0.20134897530078888, 0.3722192645072937, 0.6091946959495544, 0.41475892066955566, 0.6961155533790588], [0.0, 0.19903048872947693, 0.5915403962135315, 0.581754207611084, 0.6317610144615173, 0.6628143787384033], [0.0, 0.1961410939693451, 0.3862505257129669, 0.019876718521118164, 0.8111519813537598, 0.7314850091934204], [0.0, 0.19598299264907837, 0.7750835418701172, 0.5420777201652527, 0.8204673528671265, 0.6380487084388733], [0.0, 0.19339816272258759, 0.49518871307373047, 0.5351670384407043, 0.5448317527770996, 0.6386725306510925], [0.0, 0.19049189984798431, 0.8095263838768005, 0.5719159841537476, 0.8538216948509216, 0.6668088436126709], [0.0, 0.1879919469356537, 0.24449428915977478, 0.6283887028694153, 0.2898721992969513, 0.7228755354881287], [0.0, 0.18715043365955353, 0.7174532413482666, 0.5473859310150146, 0.7608212232589722, 0.6340204477310181], [0.0, 0.1750546544790268, 0.3978140652179718, 0.6609159708023071, 0.4442930519580841, 0.766393780708313], [0.0, 0.1739564836025238, 0.316571444272995, 0.4926838278770447, 0.5507131814956665, 1.0], [0.0, 0.17273734509944916, 0.6181405186653137, 0.6088024973869324, 0.6589571833610535, 0.7010800242424011], [0.0, 0.17174306511878967, 0.5578991174697876, 0.04314202070236206, 0.8044086694717407, 0.5945954322814941], [0.0, 0.16874855756759644, 0.563561201095581, 0.5221144556999207, 0.804703950881958, 1.0], [0.0, 0.16864216327667236, 0.0591878741979599, 0.47089070081710815, 0.31578272581100464, 1.0], [0.0, 0.16752465069293976, 0.5881549715995789, 0.6222093105316162, 0.6351147294044495, 0.7330095767974854], [0.0, 0.1659575253725052, 0.18248414993286133, 0.14801961183547974, 0.43103867769241333, 0.7201031446456909], [0.0, 0.1631908416748047, 0.7114384174346924, 0.6593426465988159, 0.760837197303772, 0.7566673755645752], [0.0, 0.1628650575876236, 0.30348700284957886, 0.5336172580718994, 0.3542736768722534, 0.6452220678329468], [0.0, 0.16273233294487, 0.7183530330657959, 0.5143589377403259, 0.7580007314682007, 0.603114664554596], [0.0, 0.16202254593372345, 0.5241270065307617, 0.5336223244667053, 0.572588324546814, 0.6394062638282776], [0.0, 0.1598389595746994, 0.46942272782325745, 0.5616849660873413, 0.5975736379623413, 0.8747552633285522], [0.0, 0.15841828286647797, 0.6888588666915894, 0.5297321081161499, 0.9280987977981567, 1.0], [0.0, 0.15804746747016907, 0.27551642060279846, 0.5404883027076721, 0.3257240355014801, 0.6348581910133362], [0.0, 0.1576952040195465, 0.43830204010009766, 0.5017617344856262, 0.6774187088012695, 1.0], [0.0, 0.15761928260326385, 0.21675434708595276, 0.6149437427520752, 0.25379282236099243, 0.6975908279418945], [0.0, 0.15181595087051392, 0.08691372722387314, 0.6075047254562378, 0.13258051872253418, 0.7025613784790039], [0.0, 0.1509828269481659, 0.7398226261138916, 0.5971165895462036, 0.7905800342559814, 0.6941225528717041], [0.0, 0.15071994066238403, 0.6929566264152527, 0.07142236828804016, 0.9341811537742615, 0.6177109479904175], [0.0, 0.1501225084066391, 0.1284576952457428, 0.06741577386856079, 0.679047703742981, 0.6960798501968384], [0.0, 0.14973950386047363, 0.3410951495170593, 0.5746504664421082, 0.3836060166358948, 0.6669875979423523], [0.0, 0.14912988245487213, 0.31142979860305786, 0.1344335675239563, 0.556283175945282, 0.7189804315567017], [0.0, 0.1485413908958435, 0.592849850654602, 0.55522620677948, 0.7242908477783203, 0.8805669546127319], [0.0, 0.14804288744926453, 0.5620525479316711, 0.4901055693626404, 0.6010157465934753, 0.575598418712616], [0.0, 0.1479552984237671, 0.3653906285762787, 0.6599792838096619, 0.41506192088127136, 0.7650359272956848], [0.0, 0.1471838653087616, 0.5643925666809082, 0.2722936272621155, 0.8019623756408691, 0.8286415934562683], [0.0, 0.14630566537380219, 0.6946133375167847, 0.30118680000305176, 0.9313726425170898, 0.8463304042816162], [0.0, 0.14570951461791992, 0.3078024387359619, 0.48555833101272583, 0.3521266579627991, 0.5755529999732971], [0.0, 0.14533762633800507, 0.08975879848003387, 0.7484879493713379, 0.13499706983566284, 0.8513010740280151], [0.0, 0.144504576921463, 0.7721772789955139, 0.5973809361457825, 0.8224675059318542, 0.7035217881202698], [0.0, 0.1434641033411026, 0.05722943693399429, 0.5807352066040039, 0.10099493712186813, 0.6691566705703735], [0.0, 0.14237385988235474, 0.4051174819469452, 0.5871525406837463, 0.4445820152759552, 0.6677692532539368], [0.0, 0.14226312935352325, 0.7048572897911072, 0.5378031730651855, 0.8296079039573669, 0.6815353631973267], [0.0, 0.142241969704628, 0.5317968726158142, 0.5546309351921082, 0.66202312707901, 0.8717586398124695], [0.0, 0.14075928926467896, 0.4947464168071747, 0.6011905074119568, 0.541083574295044, 0.7028601765632629], [0.0, 0.13910557329654694, 0.030510008335113525, 0.06189756095409393, 0.3383055031299591, 0.5361247062683105], [0.0, 0.13805723190307617, 0.5245654582977295, 0.6050918698310852, 0.5709495544433594, 0.6958295702934265], [0.0, 0.13641029596328735, 0.21110183000564575, 0.568953275680542, 0.35777562856674194, 0.8533998727798462], [0.0, 0.1352912187576294, 0.32818448543548584, 0.5691209435462952, 0.480010449886322, 0.845617949962616], [0.0, 0.13206595182418823, 0.4394766390323639, 0.26309165358543396, 0.6791475415229797, 0.8362016677856445], [0.0, 0.13116545975208282, 0.8427342176437378, 0.5772581696510315, 0.883553147315979, 0.668674886226654], [0.0, 0.12984682619571686, 0.280457466840744, 0.48422741889953613, 0.32120391726493835, 0.5718746185302734], [0.0, 0.12982621788978577, 0.5566268563270569, 0.6324587464332581, 0.6026884913444519, 0.7327890992164612], [0.0, 0.1291486620903015, 0.3062931299209595, 0.5985302329063416, 0.35245054960250854, 0.6995264887809753], [0.0, 0.12912356853485107, 0.08514228463172913, 0.5713178515434265, 0.23363345861434937, 0.8526154160499573], [0.0, 0.12716136872768402, 0.5588347315788269, 0.5776740312576294, 0.6016109585762024, 0.6657307147979736], [0.0, 0.12670114636421204, 0.05195694416761398, 0.6275805234909058, 0.1061100885272026, 0.7329729795455933], [0.0, 0.12608031928539276, 0.33587154746055603, 0.6606578230857849, 0.3859441578388214, 0.7632583975791931], [0.0, 0.12353238463401794, 0.15055623650550842, 0.582485556602478, 0.2976854741573334, 0.8570429086685181], [0.0, 0.12310735136270523, 0.37436503171920776, 0.5551080107688904, 0.41560155153274536, 0.6373888850212097], [0.0, 0.12305019795894623, 0.4910145401954651, 0.6359158158302307, 0.5376867651939392, 0.7337326407432556], [0.0, 0.12225751578807831, 0.6245548725128174, 0.5575532913208008, 0.6634032726287842, 0.6344394683837891], [0.0, 0.12155803292989731, 0.41084542870521545, 0.43489906191825867, 0.5289831161499023, 0.7606048583984375], [0.0, 0.12078040838241577, 0.5026005506515503, 0.4848041832447052, 0.5411351919174194, 0.5710885524749756], [0.0, 0.12071874737739563, 0.271780401468277, 0.6588013768196106, 0.3212535083293915, 0.7578898072242737], [0.0, 0.12071686238050461, 0.8061031699180603, 0.654290497303009, 0.8542724251747131, 0.7653856873512268], [0.0, 0.12070422619581223, 0.15115642547607422, 0.730707049369812, 0.19563481211662292, 0.8227994441986084], [0.0, 0.11793503165245056, 0.8384942412376404, 0.6311634182929993, 0.8812264800071716, 0.7298926711082458], [0.0, 0.11775515228509903, 0.11703304946422577, 0.7219545841217041, 0.1643548160791397, 0.8244591951370239], [0.0, 0.11738357692956924, 0.713188886642456, 0.6004284620285034, 0.7580609321594238, 0.6988043785095215], [0.0, 0.11615636944770813, 0.6572335958480835, 0.4398958086967468, 0.7848821878433228, 0.7513269782066345], [0.0, 0.11403921246528625, 0.46098974347114563, 0.6730154752731323, 0.5071537494659424, 0.7646503448486328], [0.0, 0.11342580616474152, 0.6219795942306519, 0.6847795844078064, 0.6650608777999878, 0.7872939705848694], [0.0, 0.1125662624835968, 0.4792080819606781, 0.4647884666919708, 0.6035784482955933, 0.6281734108924866], [0.0, 0.11255225539207458, 0.7809253334999084, 0.5007718801498413, 0.8190807700157166, 0.5776668787002563], [0.0, 0.11245988309383392, 0.465545654296875, 0.6128514409065247, 0.5097026824951172, 0.7011637091636658], [0.0, 0.11200261861085892, 0.30348142981529236, 0.658082127571106, 0.3521890938282013, 0.7559434175491333], [0.0, 0.11195290833711624, 0.682776927947998, 0.6407094597816467, 0.7296098470687866, 0.7274860739707947], [0.0, 0.11096353083848953, 0.4967745244503021, 0.6915552616119385, 0.5375094413757324, 0.7868673801422119], [0.0, 0.11076922714710236, 0.2702621817588806, 0.5745707750320435, 0.4214446544647217, 0.8472360372543335], [0.0, 0.11049393564462662, 0.1573178768157959, 0.6086278557777405, 0.19627293944358826, 0.6999565958976746], [0.0, 0.110462486743927, 0.8103564977645874, 0.5206529498100281, 0.8497604131698608, 0.6019170880317688], [0.0, 0.1093725711107254, 0.7387246489524841, 0.6575043797492981, 0.7904585003852844, 0.7584266066551208], [0.0, 0.10888044536113739, 0.5320133566856384, 0.42984139919281006, 0.6561035513877869, 0.7585813999176025], [0.0, 0.10878559201955795, 0.2182408571243286, 0.6627776622772217, 0.2589333951473236, 0.7527086734771729], [0.0, 0.10800748318433762, 0.08437858521938324, 0.657255232334137, 0.13297481834888458, 0.7608079314231873], [0.0, 0.10746277123689651, 0.4353581368923187, 0.6429815888404846, 0.47787758708000183, 0.7303568720817566], [0.0, 0.10699912160634995, 0.3341284990310669, 0.7501580119132996, 0.38074398040771484, 0.8465656638145447], [0.0, 0.10680369287729263, 0.4701295793056488, 0.4246355891227722, 0.5933416485786438, 0.7536581158638], [0.0, 0.10679493099451065, 0.6871690154075623, 0.5780066847801208, 0.7266059517860413, 0.6636163592338562], [0.0, 0.10673461109399796, 0.21717488765716553, 0.4365362226963043, 0.34597039222717285, 0.7503812313079834], [0.0, 0.10605885833501816, 0.20671865344047546, 0.5955837368965149, 0.32764413952827454, 0.7500222325325012], [0.0, 0.10551788657903671, 0.18639345467090607, 0.6157762408256531, 0.22453148663043976, 0.7027449011802673], [0.0, 0.10529094189405441, 0.3883190155029297, 0.5705198645591736, 0.5446224212646484, 0.8447068333625793], [0.0, 0.10520854592323303, 0.37017807364463806, 0.7115764617919922, 0.41594019532203674, 0.8179439306259155], [0.0, 0.1050594225525856, 0.04995083808898926, 0.6867724657058716, 0.10429725050926208, 0.7957525253295898], [0.0, 0.10501474142074585, 0.18659710884094238, 0.7438626289367676, 0.6467540264129639, 1.0], [0.0, 0.10453720390796661, 0.7193110585212708, 0.4335719347000122, 0.843771755695343, 0.7446821928024292], [0.0, 0.10443896800279617, 0.6543832421302795, 0.6109048128128052, 0.6950374245643616, 0.6933633089065552], [0.0, 0.10388503968715668, 0.055680736899375916, 0.2686953544616699, 0.31665927171707153, 0.7974050045013428], [0.0, 0.10324737429618835, 0.43057143688201904, 0.6953613758087158, 0.47599977254867554, 0.7926826477050781], [0.0, 0.10315928608179092, 0.34354162216186523, 0.4331206977367401, 0.469091534614563, 0.7592951059341431], [0.0, 0.10262981057167053, 0.3958450257778168, 0.712478518486023, 0.4480203688144684, 0.8188124895095825], [0.0, 0.10225443542003632, 0.21890637278556824, 0.5856008529663086, 0.2558596134185791, 0.6659497022628784], [0.0, 0.10192757099866867, 0.3385755121707916, 0.5181629657745361, 0.38261422514915466, 0.6031529903411865], [0.0, 0.10169833153486252, 0.1534593403339386, 0.666952908039093, 0.28566521406173706, 1.0], [0.0, 0.10144077241420746, 0.28010043501853943, 0.4527139961719513, 0.405904620885849, 0.7520546913146973], [0.0, 0.10142262279987335, 0.12105170637369156, 0.610508382320404, 0.16238778829574585, 0.6994649767875671], [0.0, 0.10111970454454422, 0.7157222032546997, 0.615729570388794, 0.8421378135681152, 0.9306517839431763], [0.0, 0.10093370825052261, 0.7726397514343262, 0.6568724513053894, 0.823075532913208, 0.7554672360420227], [0.0, 0.09959379583597183, 0.08351237326860428, 0.0, 0.22554299235343933, 0.2351546287536621], [0.0, 0.09941046684980392, 0.24429701268672943, 0.7222362160682678, 0.29048964381217957, 0.8180298209190369], [0.0, 0.09890595823526382, 0.6519976854324341, 0.6947783827781677, 0.6929613351821899, 0.7829598784446716], [0.0, 0.09761245548725128, 0.8722689151763916, 0.48356929421424866, 0.9163399934768677, 0.5729783177375793], [0.0, 0.09756910800933838, 0.15186792612075806, 0.6781096458435059, 0.19495448470115662, 0.7587707042694092], [0.0, 0.0973474308848381, 0.6000891327857971, 0.0, 1.0, 0.43092912435531616], [0.0, 0.09722822904586792, 0.21715372800827026, 0.6714656949043274, 0.3462384343147278, 0.9966832995414734], [0.0, 0.09646198898553848, 0.593303382396698, 0.43046894669532776, 0.7206388115882874, 0.7562488317489624], [0.0, 0.09591855108737946, 0.7184367775917053, 0.0, 0.843657910823822, 0.31335437297821045], [0.0, 0.0950610563158989, 0.7551252245903015, 0.5634885430335999, 0.8848256468772888, 0.7134326100349426], [0.0, 0.09498118609189987, 0.8303303122520447, 0.5163195729255676, 0.9752897620201111, 0.7925637364387512], [0.0, 0.094974584877491, 0.21645072102546692, 0.695480227470398, 0.25838565826416016, 0.7910357713699341], [0.0, 0.09465650469064713, 0.8378569483757019, 0.6913176774978638, 0.8806176781654358, 0.7867519855499268], [0.0, 0.09444479644298553, 0.78011155128479, 0.4297196567058563, 0.9081118106842041, 0.7317142486572266], [0.0, 0.09444291889667511, 0.02209349349141121, 0.6961196660995483, 0.0760200172662735, 0.7939413785934448], [0.0, 0.09425824135541916, 0.29206621646881104, 0.659156322479248, 0.4154798984527588, 0.8014664649963379], [0.0, 0.09409983456134796, 0.5235309600830078, 0.6680706143379211, 0.5725849866867065, 0.7608492970466614], [0.0, 0.09373966604471207, 0.48437657952308655, 0.5310750603675842, 0.6098812818527222, 0.683155357837677], [0.0, 0.09239447861909866, 0.5524583458900452, 0.6944584250450134, 0.6022362112998962, 0.7902957797050476], [0.0, 0.09221728891134262, 0.24154390394687653, 0.6638628244400024, 0.2891193628311157, 0.7584583759307861], [0.0, 0.09201807528734207, 0.12017585337162018, 0.6756914258003235, 0.1639118641614914, 0.7626580595970154], [0.0, 0.0918574258685112, 0.27313801646232605, 0.6066480278968811, 0.32035693526268005, 0.7049900889396667], [0.0, 0.09165716171264648, 0.7816800475120544, 0.004877418279647827, 0.9062677025794983, 0.31426092982292175], [0.0, 0.09131090342998505, 0.5938567519187927, 0.6811455488204956, 0.7233607172966003, 1.0], [0.0, 0.09108845889568329, 0.15180331468582153, 0.5444561839103699, 0.19686535000801086, 0.6349369883537292], [0.0, 0.09107339382171631, 0.18539291620254517, 0.6734154224395752, 0.22672486305236816, 0.7581871747970581], [0.0, 0.09084777534008026, 0.6998978853225708, 0.6342865824699402, 0.8337007761001587, 0.7803856730461121], [0.0, 0.09039173275232315, 0.8441814184188843, 0.608527660369873, 0.9740020036697388, 0.9350574016571045], [0.0, 0.09027961641550064, 0.14320653676986694, 0.39731365442276, 0.2980556786060333, 0.6712465882301331], [0.0, 0.08999139815568924, 0.6472528576850891, 0.32927238941192627, 0.7911826968193054, 0.6106887459754944], [0.0, 0.08994369208812714, 0.09079889208078384, 0.7424211502075195, 0.22441253066062927, 1.0], [0.0, 0.089527428150177, 0.46689534187316895, 0.5496869087219238, 0.506982684135437, 0.6316518783569336], [0.0, 0.08952119201421738, 0.015685804188251495, 0.6257084608078003, 0.14607813954353333, 0.7787766456604004], [0.0, 0.08790803700685501, 0.2681914269924164, 0.7528401613235474, 0.3192446529865265, 0.8475961685180664], [0.0, 0.08784860372543335, 0.5453982353210449, 0.5712602138519287, 0.6647201776504517, 0.7250183820724487], [0.0, 0.08737348765134811, 0.8401806950569153, 0.5118048191070557, 0.8834193348884583, 0.6050533056259155], [0.0, 0.08687499910593033, 0.2572770118713379, 0.5985057950019836, 0.3924160599708557, 0.7447341084480286], [0.0, 0.08668716996908188, 0.39536815881729126, 0.325509250164032, 0.5433145761489868, 0.6049622893333435], [0.0, 0.08646100014448166, 0.4307592809200287, 0.0, 0.6734514832496643, 0.45779329538345337], [0.0, 0.08640647679567337, 0.025981970131397247, 0.7502849698066711, 0.06904345005750656, 0.8499683737754822], [0.0, 0.08600539714097977, 0.22861436009407043, 0.6931702494621277, 0.3628142774105072, 0.8370785117149353], [0.0, 0.08559911698102951, 0.2990586757659912, 0.747231662273407, 0.3511323928833008, 0.8473243117332458], [0.0, 0.08531323820352554, 0.512067973613739, 0.6283495426177979, 0.6428684592247009, 0.7677013874053955], [0.0, 0.0848710760474205, 0.1882665455341339, 0.5816168189048767, 0.22689419984817505, 0.6697099804878235], [0.0, 0.08442327380180359, 0.02443554252386093, 0.550881028175354, 0.16402587294578552, 0.8613334894180298], [0.0, 0.08387446403503418, 0.1556515246629715, 0.6461442112922668, 0.19789321720600128, 0.7291460633277893]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "object_detector.content_type = 'image/jpeg'\n",
    "results = object_detector.predict(b)\n",
    "detections = json.loads(results)\n",
    "print (detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = dict()\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n",
    "                                 ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id],\n",
    "                                 linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object_categories = ['person', 'bicycle', 'car',  'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', \n",
    "                     'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
    "                     'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "                     'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
    "                     'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable',\n",
    "                     'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
    "                     'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "                     'toothbrush']\n",
    "# Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20.\n",
    "threshold = 0.20\n",
    "\n",
    "# Visualize the detections.\n",
    "visualize_detection(file_name, detections['prediction'], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker.Session().delete_endpoint(object_detector.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
