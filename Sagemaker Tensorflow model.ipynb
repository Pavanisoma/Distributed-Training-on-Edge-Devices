{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_uri = 's3://sagemaker-sample-data-{}/tensorflow/mnist'.format(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2018-2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\n",
      "\u001b[33m\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m division\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow.python.platform\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tf_logging\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_logging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_sys\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcnn_model_fn\u001b[39;49;00m(features, labels, mode):\n",
      "    \u001b[33m\"\"\"Model function for CNN.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[37m# Input Layer\u001b[39;49;00m\n",
      "    \u001b[37m# Reshape X to 4-D tensor: [batch_size, width, height, channels]\u001b[39;49;00m\n",
      "    \u001b[37m# MNIST images are 28x28 pixels, and have one color channel\u001b[39;49;00m\n",
      "    input_layer = tf.reshape(features[\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], [-\u001b[34m1\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Convolutional Layer #1\u001b[39;49;00m\n",
      "    \u001b[37m# Computes 32 features using a 5x5 filter with ReLU activation.\u001b[39;49;00m\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 1]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\n",
      "    conv1 = tf.layers.conv2d(\n",
      "        inputs=input_layer,\n",
      "        filters=\u001b[34m32\u001b[39;49;00m,\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Pooling Layer #1\u001b[39;49;00m\n",
      "    \u001b[37m# First max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Convolutional Layer #2\u001b[39;49;00m\n",
      "    \u001b[37m# Computes 64 features using a 5x5 filter.\u001b[39;49;00m\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\n",
      "    conv2 = tf.layers.conv2d(\n",
      "        inputs=pool1,\n",
      "        filters=\u001b[34m64\u001b[39;49;00m,\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Pooling Layer #2\u001b[39;49;00m\n",
      "    \u001b[37m# Second max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Flatten tensor into a batch of vectors\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\n",
      "    pool2_flat = tf.reshape(pool2, [-\u001b[34m1\u001b[39;49;00m, \u001b[34m7\u001b[39;49;00m * \u001b[34m7\u001b[39;49;00m * \u001b[34m64\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Dense Layer\u001b[39;49;00m\n",
      "    \u001b[37m# Densely connected layer with 1024 neurons\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Add dropout operation; 0.6 probability that element will be kept\u001b[39;49;00m\n",
      "    dropout = tf.layers.dropout(\n",
      "        inputs=dense, rate=\u001b[34m0.4\u001b[39;49;00m, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
      "\n",
      "    \u001b[37m# Logits layer\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 10]\u001b[39;49;00m\n",
      "    logits = tf.layers.dense(inputs=dropout, units=\u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    predictions = {\n",
      "        \u001b[37m# Generate predictions (for PREDICT and EVAL mode)\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.argmax(\u001b[36minput\u001b[39;49;00m=logits, axis=\u001b[34m1\u001b[39;49;00m),\n",
      "        \u001b[37m# Add `softmax_tensor` to the graph. It is used for PREDICT and by the\u001b[39;49;00m\n",
      "        \u001b[37m# `logging_hook`.\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.nn.softmax(logits, name=\u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    }\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.PREDICT:\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
      "\n",
      "    \u001b[37m# Calculate Loss (for both TRAIN and EVAL modes)\u001b[39;49;00m\n",
      "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
      "\n",
      "    \u001b[37m# Configure the Training Op (for TRAIN mode)\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.TRAIN:\n",
      "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=\u001b[34m0.001\u001b[39;49;00m)\n",
      "      train_op = optimizer.minimize(\n",
      "          loss=loss,\n",
      "          global_step=tf.train.get_global_step())\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
      "\n",
      "    \u001b[37m# Add evaluation metrics (for EVAL mode)\u001b[39;49;00m\n",
      "    eval_metric_ops = {\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.metrics.accuracy(\n",
      "            labels=labels, predictions=predictions[\u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])}\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(\n",
      "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mserving_input_fn\u001b[39;49;00m():\n",
      "    inputs = {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.placeholder(tf.float32, [\u001b[36mNone\u001b[39;49;00m, \u001b[34m784\u001b[39;49;00m])}\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    \u001b[37m# Create the Estimator\u001b[39;49;00m\n",
      "    mnist_classifier = tf.estimator.Estimator(\n",
      "        model_fn=cnn_model_fn, model_dir=args.model_dir)\n",
      "\n",
      "    \u001b[37m# Set up logging for predictions\u001b[39;49;00m\n",
      "    \u001b[37m# Log the values in the \"Softmax\" tensor with label \"probabilities\"\u001b[39;49;00m\n",
      "    tensors_to_log = {\u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}\n",
      "    logging_hook = tf.train.LoggingTensorHook(\n",
      "        tensors=tensors_to_log, every_n_iter=\u001b[34m50\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\n",
      "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: train_data},\n",
      "        y=train_labels,\n",
      "        batch_size=\u001b[34m100\u001b[39;49;00m,\n",
      "        num_epochs=\u001b[36mNone\u001b[39;49;00m,\n",
      "        shuffle=\u001b[36mTrue\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Evaluate the model and print results\u001b[39;49;00m\n",
      "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: eval_data},\n",
      "        y=eval_labels,\n",
      "        num_epochs=\u001b[34m1\u001b[39;49;00m,\n",
      "        shuffle=\u001b[36mFalse\u001b[39;49;00m)\n",
      "\n",
      "    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=\u001b[34m20000\u001b[39;49;00m)\n",
      "    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n",
      "    tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        mnist_classifier.export_savedmodel(args.sm_model_dir, serving_input_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\r\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\r\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\r\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\r\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\r\n",
      "\u001b[37m# language governing permissions and limitations under the License.import tensorflow as tf\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(x_train, y_train, x_test, y_test):\r\n",
      "    \u001b[33m\"\"\"Generate a simple model\"\"\"\u001b[39;49;00m\r\n",
      "    model = tf.keras.models.Sequential([\r\n",
      "        tf.keras.layers.Flatten(),\r\n",
      "        tf.keras.layers.Dense(\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu),\r\n",
      "        tf.keras.layers.Dropout(\u001b[34m0.4\u001b[39;49;00m),\r\n",
      "        tf.keras.layers.Dense(\u001b[34m10\u001b[39;49;00m, activation=tf.nn.softmax)\r\n",
      "    ])\r\n",
      "\r\n",
      "    model.compile(optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                  loss=\u001b[33m'\u001b[39;49;00m\u001b[33msparse_categorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    model.fit(x_train, y_train)\r\n",
      "    model.evaluate(x_test, y_test)\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\r\n",
      "    \u001b[33m\"\"\"Load MNIST training data\"\"\"\u001b[39;49;00m\r\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\r\n",
      "    \u001b[33m\"\"\"Load MNIST testing data\"\"\"\u001b[39;49;00m\r\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\r\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    args, unknown = _parse_args()\r\n",
      "\r\n",
      "    train_data, train_labels = _load_training_data(args.train)\r\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\r\n",
      "\r\n",
      "    mnist_classifier = model(train_data, train_labels, eval_data, eval_labels)\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\r\n",
      "        \u001b[37m# save model to an S3 directory with version number '00000001'\u001b[39;49;00m\r\n",
      "        mnist_classifier.save(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33m000000001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mmy_model.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'mnist.py'\n",
    "\n",
    "# TensorFlow 2.1 script\n",
    "!pygmentize 'mnist-2.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='1.15.2',\n",
    "                             py_version='py3',\n",
    "                             distributions={'parameter_server': {'enabled': True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_estimator2 = TensorFlow(entry_point='mnist-2.py',\n",
    "                             role=role,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='2.1.0',\n",
    "                             py_version='py3',\n",
    "                             distributions={'parameter_server': {'enabled': True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 06:23:37 Starting - Starting the training job...\n",
      "2020-04-11 06:23:38 Starting - Launching requested ML instances......\n",
      "2020-04-11 06:24:44 Starting - Preparing the instances for training......\n",
      "2020-04-11 06:25:51 Downloading - Downloading input data...\n",
      "2020-04-11 06:26:35 Training - Downloading the training image...\n",
      "2020-04-11 06:26:59 Training - Training image download completed. Training in progress..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-11 06:27:02,291 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:03,464 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:03,724 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:03,725 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:03,725 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:03,725 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:03,726 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:04,334 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[35m2020-04-11 06:27:04,573 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"tensorflow-training-2020-04-11-06-23-37-133\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"tensorflow-training-2020-04-11-06-23-37-133\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\u001b[0m\n",
      "\u001b[35mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/bin/python3 mnist.py --model_dir s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-04-11 06:28:02,855 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2020-04-11 06:28:02,855 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2020-04-11 06:28:02,855 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-11 06:28:02,856 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-11 06:28:02,856 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-11 06:28:03,494 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34m2020-04-11 06:28:03,790 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2020-04-11-06-23-37-133\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-04-11-06-23-37-133\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\u001b[0m\n",
      "\u001b[34mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 mnist.py --model_dir s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mINFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, conv2d/kernel, conv2d/bias, conv2d_1/kernel, conv2d_1/bias, dense/kernel, dense/bias, dense_1/kernel, dense_1/bias, ready: None\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, conv2d/kernel, conv2d/bias, conv2d_1/kernel, conv2d_1/bias, dense/kernel, dense/bias, dense_1/kernel, dense_1/bias, ready: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 0 into s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 0 into s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.3064835, step = 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.3064835, step = 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2859502, step = 100 (3.921 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2859502, step = 100 (3.921 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.254363, step = 200 (3.772 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.254363, step = 200 (3.772 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2423103, step = 300 (3.759 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2423103, step = 300 (3.759 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2105987, step = 400 (3.748 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2105987, step = 400 (3.748 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.1526816, step = 500 (3.735 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.1526816, step = 500 (3.735 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.122567, step = 600 (3.744 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.122567, step = 600 (3.744 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0927238, step = 700 (3.744 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0927238, step = 700 (3.744 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0444837, step = 800 (3.754 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0444837, step = 800 (3.754 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.9073851, step = 900 (3.751 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.9073851, step = 900 (3.751 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.8201162, step = 1000 (3.742 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.8201162, step = 1000 (3.742 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.6246235, step = 1100 (3.765 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.6246235, step = 1100 (3.765 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.724926, step = 1012\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.724926, step = 1012\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1461\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1461\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.3485492, step = 1300 (3.904 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.3485492, step = 1300 (3.904 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.2880187, step = 1301 (3.232 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.2880187, step = 1301 (3.232 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.847\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.847\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.87288994, step = 1543 (3.953 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.87288994, step = 1543 (3.953 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.0779\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.0779\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.98050743, step = 1470 (2.739 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.98050743, step = 1470 (2.739 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.8784\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.8784\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.6797\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.6797\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.8275004, step = 1639 (2.729 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.8275004, step = 1639 (2.729 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0873\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0873\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.7383856, step = 1790 (4.054 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.7383856, step = 1790 (4.054 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7819103, step = 1807 (2.789 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7819103, step = 1807 (2.789 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.9126\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.9126\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.4752\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.4752\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7820505, step = 1974 (2.687 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7820505, step = 1974 (2.687 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.7169721, step = 2037 (3.985 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.7169721, step = 2037 (3.985 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2703\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2703\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0777\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0777\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5151251, step = 2141 (2.654 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5151251, step = 2141 (2.654 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.6295\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.6295\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.68379563, step = 2309 (2.695 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.68379563, step = 2309 (2.695 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5419672, step = 2286 (3.991 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5419672, step = 2286 (3.991 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2255\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2255\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7094\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7094\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.6367778, step = 2477 (2.790 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.6367778, step = 2477 (2.790 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5745302, step = 2531 (4.026 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5745302, step = 2531 (4.026 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0082\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0082\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1134\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1134\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.46250775, step = 2647 (2.845 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.46250775, step = 2647 (2.845 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5093\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5093\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.44865987, step = 2816 (2.912 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.44865987, step = 2816 (2.912 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8919\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8919\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:tensorflow:loss = 0.41273543, step = 2777 (4.202 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.41273543, step = 2777 (4.202 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6708\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6708\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.6564521, step = 3019 (4.089 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.6564521, step = 3019 (4.089 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.38484222, step = 2986 (2.863 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.38484222, step = 2986 (2.863 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.3872\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.3872\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6268\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6268\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.37884548, step = 3154 (2.840 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.37884548, step = 3154 (2.840 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.37648553, step = 3268 (4.191 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.37648553, step = 3268 (4.191 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3534737, step = 3508 (4.117 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3534737, step = 3508 (4.117 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3683\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3683\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.26748797, step = 3322 (2.809 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.26748797, step = 3322 (2.809 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.2671\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.2671\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.7572\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.7572\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.46568152, step = 3493 (2.942 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.46568152, step = 3493 (2.942 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1211\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1211\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.6726\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.6726\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29990375, step = 3665 (2.870 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29990375, step = 3665 (2.870 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.43284458, step = 3748 (4.026 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.43284458, step = 3748 (4.026 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5988\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5988\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.45480263, step = 3835 (2.898 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.45480263, step = 3835 (2.898 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9994\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9994\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.9098\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.9098\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2929904, step = 4005 (2.817 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2929904, step = 4005 (2.817 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5418\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5418\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32071745, step = 3992 (4.079 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32071745, step = 3992 (4.079 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.477\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.477\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.48076275, step = 4174 (2.851 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.48076275, step = 4174 (2.851 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.24816944, step = 4236 (4.096 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.24816944, step = 4236 (4.096 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6248\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6248\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32844573, step = 4343 (2.832 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32844573, step = 4343 (2.832 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6739\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6739\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0255\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0255\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23788337, step = 4481 (4.067 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23788337, step = 4481 (4.067 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.335141, step = 4512 (2.763 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.335141, step = 4512 (2.763 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5014\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5014\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2465\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2465\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1592388, step = 4681 (2.804 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1592388, step = 4681 (2.804 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.41390306, step = 4727 (4.088 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.41390306, step = 4727 (4.088 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5122\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5122\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3272061, step = 4851 (2.981 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3272061, step = 4851 (2.981 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.9936\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.9936\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20959705, step = 4969 (4.281 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20959705, step = 4969 (4.281 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.111\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.111\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35200608, step = 5020 (2.960 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35200608, step = 5020 (2.960 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8357\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8357\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7477\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7477\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.33889794, step = 5212 (4.118 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.33889794, step = 5212 (4.118 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29167753, step = 5191 (2.909 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29167753, step = 5191 (2.909 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8191\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8191\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2859944, step = 5361 (2.850 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2859944, step = 5361 (2.850 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8057\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8057\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16738652, step = 5457 (4.103 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16738652, step = 5457 (4.103 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.2932\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.2932\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.28416893, step = 5530 (2.839 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.28416893, step = 5530 (2.839 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7781\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7781\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3676809, step = 5702 (4.133 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3676809, step = 5702 (4.133 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0905\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0905\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.26266652, step = 5698 (2.811 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.26266652, step = 5698 (2.811 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2222\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2222\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21208504, step = 5866 (2.887 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21208504, step = 5866 (2.887 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0347\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0347\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23566568, step = 5950 (4.191 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23566568, step = 5950 (4.191 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0272\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0272\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23981453, step = 6033 (2.780 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23981453, step = 6033 (2.780 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.2127\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.2127\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.405\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.405\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28079215, step = 6199 (4.071 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28079215, step = 6199 (4.071 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.39148122, step = 6200 (2.687 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.39148122, step = 6200 (2.687 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5711\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5711\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19079633, step = 6367 (2.797 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19079633, step = 6367 (2.797 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0542\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0542\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5217\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5217\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19974697, step = 6535 (2.708 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19974697, step = 6535 (2.708 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:tensorflow:loss = 0.3932623, step = 6448 (4.110 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3932623, step = 6448 (4.110 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5067\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5067\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3201\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3201\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2949022, step = 6696 (3.950 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2949022, step = 6696 (3.950 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10603148, step = 6701 (2.615 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10603148, step = 6701 (2.615 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2711\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2711\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32965377, step = 6868 (2.624 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32965377, step = 6868 (2.624 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6201\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6201\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5427\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5427\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.118583545, step = 7034 (2.755 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.118583545, step = 7034 (2.755 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0337\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0337\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11298564, step = 6948 (4.040 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11298564, step = 6948 (4.040 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.21849906, step = 7199 (4.143 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.21849906, step = 7199 (4.143 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.6371\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.6371\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2435824, step = 7200 (2.759 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2435824, step = 7200 (2.759 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0637\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0637\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24086887, step = 7369 (2.773 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24086887, step = 7369 (2.773 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5219\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5219\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.26469716, step = 7447 (4.086 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.26469716, step = 7447 (4.086 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.45\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.45\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.30046833, step = 7534 (2.686 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.30046833, step = 7534 (2.686 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.7952\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.7952\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28694075, step = 7695 (4.009 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28694075, step = 7695 (4.009 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0264\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0264\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.48031121, step = 7702 (2.715 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.48031121, step = 7702 (2.715 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5811\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5811\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17475106, step = 7869 (2.671 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17475106, step = 7869 (2.671 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.3141\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.3141\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28161803, step = 7944 (4.020 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28161803, step = 7944 (4.020 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.6543\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.6543\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.36351925, step = 8038 (2.822 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.36351925, step = 8038 (2.822 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1872\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1872\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.21779239, step = 8193 (4.149 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.21779239, step = 8193 (4.149 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5205\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5205\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27057105, step = 8204 (2.751 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27057105, step = 8204 (2.751 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.431\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.431\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27138522, step = 8370 (2.620 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27138522, step = 8370 (2.620 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5922\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5922\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32948166, step = 8437 (3.970 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32948166, step = 8437 (3.970 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.0872\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.0872\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20078047, step = 8544 (2.975 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20078047, step = 8544 (2.975 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0671\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0671\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13119178, step = 8682 (4.073 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13119178, step = 8682 (4.073 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.9946\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.9946\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22259533, step = 8712 (2.745 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22259533, step = 8712 (2.745 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.596\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.596\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14806609, step = 8879 (2.784 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14806609, step = 8879 (2.784 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28159893, step = 8930 (4.091 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28159893, step = 8930 (4.091 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.971\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.971\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.3216\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.3216\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.28356397, step = 9045 (2.715 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.28356397, step = 9045 (2.715 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.1463\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.1463\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1653919, step = 9181 (4.109 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1653919, step = 9181 (4.109 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0578\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0578\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.26267147, step = 9212 (2.740 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.26267147, step = 9212 (2.740 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8278\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8278\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20246819, step = 9378 (2.758 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20246819, step = 9378 (2.758 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1967\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1967\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.2738\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.2738\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2482018, step = 9544 (2.749 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2482018, step = 9544 (2.749 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5278\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5278\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.21829951, step = 9432 (4.188 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.21829951, step = 9432 (4.188 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18488719, step = 9680 (4.061 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18488719, step = 9680 (4.061 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16630396, step = 9713 (2.801 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16630396, step = 9713 (2.801 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4809\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4809\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0855\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0855\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17669323, step = 9882 (2.798 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17669323, step = 9882 (2.798 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6526\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6526\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11432561, step = 9927 (4.080 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11432561, step = 9927 (4.080 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.902\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.902\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11175456, step = 10048 (2.630 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11175456, step = 10048 (2.630 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2954\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2954\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.30266723, step = 10177 (3.971 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.30266723, step = 10177 (3.971 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27076527, step = 10214 (2.631 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27076527, step = 10214 (2.631 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0886\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0886\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1156\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1156\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2022133, step = 10380 (2.623 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2022133, step = 10380 (2.623 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1721\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1721\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28531587, step = 10428 (3.970 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.28531587, step = 10428 (3.970 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.943\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.943\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20887709, step = 10548 (2.680 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20887709, step = 10548 (2.680 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.9995\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.9995\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23837204, step = 10675 (3.941 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23837204, step = 10675 (3.941 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15676248, step = 10717 (2.697 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15676248, step = 10717 (2.697 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.795\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.795\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.475\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.475\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35655108, step = 10885 (2.677 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35655108, step = 10885 (2.677 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.4454\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.4454\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.08698311, step = 10922 (3.939 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.08698311, step = 10922 (3.939 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6265\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6265\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20416076, step = 11051 (2.647 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20416076, step = 11051 (2.647 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8728\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8728\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25398168, step = 11171 (3.973 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25398168, step = 11171 (3.973 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15902711, step = 11218 (2.641 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15902711, step = 11218 (2.641 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.646\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.646\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7038\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7038\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23475087, step = 11385 (2.692 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23475087, step = 11385 (2.692 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12565118, step = 11421 (3.974 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12565118, step = 11421 (3.974 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6966\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6966\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0832\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0832\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10112179, step = 11552 (2.635 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10112179, step = 11552 (2.635 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13306257, step = 11670 (3.955 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13306257, step = 11670 (3.955 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9568\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9568\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16282694, step = 11720 (2.677 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16282694, step = 11720 (2.677 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5561\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5561\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5318\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5318\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20932129, step = 11918 (3.947 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20932129, step = 11918 (3.947 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15323123, step = 11887 (2.662 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15323123, step = 11887 (2.662 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5921\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5921\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25211772, step = 12170 (3.984 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25211772, step = 12170 (3.984 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.7235\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.7235\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16595595, step = 12053 (2.601 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16595595, step = 12053 (2.601 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.8402\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.8402\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11338788, step = 12219 (2.639 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11338788, step = 12219 (2.639 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.235\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.235\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.8899\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.8899\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17928122, step = 12421 (3.946 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17928122, step = 12421 (3.946 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11614015, step = 12386 (2.614 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11614015, step = 12386 (2.614 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.6252\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.6252\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3464\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3464\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07913173, step = 12552 (2.633 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07913173, step = 12552 (2.633 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1919413, step = 12672 (3.973 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1919413, step = 12672 (3.973 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.73\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.73\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15088218, step = 12719 (2.651 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15088218, step = 12719 (2.651 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7627\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7627\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0592\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0592\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.26383922, step = 12921 (3.938 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.26383922, step = 12921 (3.938 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12566397, step = 12885 (2.626 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12566397, step = 12885 (2.626 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 64.2093\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 64.2093\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 64.0069\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 64.0069\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1755813, step = 13051 (2.601 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1755813, step = 13051 (2.601 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16318098, step = 13173 (3.953 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16318098, step = 13173 (3.953 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5788\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5788\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2647111, step = 13217 (2.607 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2647111, step = 13217 (2.607 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9071\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9071\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1303\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1303\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1982691, step = 13384 (2.680 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1982691, step = 13384 (2.680 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16202839, step = 13423 (3.975 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16202839, step = 13423 (3.975 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3781\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3781\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 64.3815\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 64.3815\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14927524, step = 13551 (2.608 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14927524, step = 13551 (2.608 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1488633, step = 13673 (3.949 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1488633, step = 13673 (3.949 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0613\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0613\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17056686, step = 13716 (2.616 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17056686, step = 13716 (2.616 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0642\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0642\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.9028\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.9028\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21951343, step = 13883 (2.628 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21951343, step = 13883 (2.628 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5034\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.5034\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:tensorflow:loss = 0.2717082, step = 13925 (3.972 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2717082, step = 13925 (3.972 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21605453, step = 14049 (2.613 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21605453, step = 14049 (2.613 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3772\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3772\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.08552087, step = 14176 (3.950 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.08552087, step = 14176 (3.950 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.609\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.609\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.052379318, step = 14215 (2.618 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.052379318, step = 14215 (2.618 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2904\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2904\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.4772\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.4772\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.25210628, step = 14384 (2.695 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.25210628, step = 14384 (2.695 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13914593, step = 14424 (3.950 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13914593, step = 14424 (3.950 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0461\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.0461\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12862939, step = 14549 (2.612 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12862939, step = 14549 (2.612 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8834\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8834\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18303104, step = 14674 (3.972 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18303104, step = 14674 (3.972 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1591\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1591\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07289253, step = 14717 (2.701 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07289253, step = 14717 (2.701 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.8844\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.8844\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.722\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.722\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15594956, step = 14886 (2.730 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15594956, step = 14886 (2.730 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11349677, step = 14920 (3.966 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11349677, step = 14920 (3.966 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5559\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5559\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2424942, step = 15054 (2.681 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2424942, step = 15054 (2.681 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8521\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8521\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20782547, step = 15167 (3.963 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20782547, step = 15167 (3.963 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3295\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3295\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16671011, step = 15221 (2.677 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16671011, step = 15221 (2.677 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5028\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5028\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2152\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.2152\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.28444308, step = 15389 (2.681 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.28444308, step = 15389 (2.681 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.06271481, step = 15416 (3.962 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.06271481, step = 15416 (3.962 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3428\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3428\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14587916, step = 15557 (2.681 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14587916, step = 15557 (2.681 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.4699\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.4699\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14639753, step = 15662 (3.952 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14639753, step = 15662 (3.952 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.282\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.282\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19473465, step = 15725 (2.679 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19473465, step = 15725 (2.679 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5839\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5839\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9148\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9148\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10128637, step = 15891 (2.664 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10128637, step = 15891 (2.664 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13512321, step = 15913 (3.989 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13512321, step = 15913 (3.989 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6234\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6234\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14945903, step = 16064 (2.845 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14945903, step = 16064 (2.845 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3701\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.3701\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17018333, step = 16154 (3.943 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17018333, step = 16154 (3.943 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6562\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6562\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18251503, step = 16230 (2.649 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18251503, step = 16230 (2.649 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1188\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.1188\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7969\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7969\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15926301, step = 16398 (2.675 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15926301, step = 16398 (2.675 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16454269, step = 16402 (3.950 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16454269, step = 16402 (3.950 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.833\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.833\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16940384, step = 16564 (2.623 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16940384, step = 16564 (2.623 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.4141\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 63.4141\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.109440915, step = 16652 (3.961 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.109440915, step = 16652 (3.961 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5421\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5421\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10903159, step = 16732 (2.694 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10903159, step = 16732 (2.694 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5391\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5391\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6765\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6765\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17670609, step = 16899 (2.672 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17670609, step = 16899 (2.672 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19424511, step = 16900 (3.971 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19424511, step = 16900 (3.971 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.6086\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.6086\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13663082, step = 17069 (2.745 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13663082, step = 17069 (2.745 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3693\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3693\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25038636, step = 17145 (3.945 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25038636, step = 17145 (3.945 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8774\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.8774\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16416527, step = 17236 (2.664 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16416527, step = 17236 (2.664 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5418\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.5418\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2841\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2841\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17200743, step = 17392 (3.962 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17200743, step = 17392 (3.962 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12843499, step = 17405 (2.723 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12843499, step = 17405 (2.723 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2429\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2429\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14132658, step = 17573 (2.680 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14132658, step = 17573 (2.680 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13451456, step = 17640 (3.969 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.13451456, step = 17640 (3.969 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9346\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9346\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5471\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5471\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09369166, step = 17740 (2.682 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09369166, step = 17740 (2.682 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1627\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1627\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:tensorflow:loss = 0.19725126, step = 17887 (3.966 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19725126, step = 17887 (3.966 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6001\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.6001\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12044866, step = 17908 (2.699 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12044866, step = 17908 (2.699 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5063\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5063\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.120877884, step = 18076 (2.687 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.120877884, step = 18076 (2.687 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.07618893, step = 18134 (3.953 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.07618893, step = 18134 (3.953 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2383\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2383\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3686\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3686\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13385777, step = 18243 (2.664 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13385777, step = 18243 (2.664 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9172\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.9172\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.9199\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.9199\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23820147, step = 18411 (2.702 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23820147, step = 18411 (2.702 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.123\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.123\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.07791914, step = 18383 (3.986 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.07791914, step = 18383 (3.986 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06878873, step = 18580 (2.731 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06878873, step = 18580 (2.731 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.087140754, step = 18628 (3.947 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.087140754, step = 18628 (3.947 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.8099\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.8099\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7338\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.7338\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06009761, step = 18748 (2.680 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06009761, step = 18748 (2.680 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.9283\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.9283\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19835296, step = 18876 (3.976 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19835296, step = 18876 (3.976 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.046903916, step = 19123 (3.970 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.046903916, step = 19123 (3.970 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.4481\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.4481\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.107989505, step = 18916 (2.721 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.107989505, step = 18916 (2.721 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1609\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1609\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.110728405, step = 19084 (2.679 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.110728405, step = 19084 (2.679 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5437\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.5437\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.2752\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.2752\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13223444, step = 19252 (2.732 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13223444, step = 19252 (2.732 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.9638\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.9638\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2343541, step = 19366 (3.975 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2343541, step = 19366 (3.975 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.3962\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.3962\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15578198, step = 19422 (2.778 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15578198, step = 19422 (2.778 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.054612145, step = 19615 (4.011 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.054612145, step = 19615 (4.011 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2431\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.2431\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14336926, step = 19589 (2.694 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14336926, step = 19589 (2.694 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1088\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.1088\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0992\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.0992\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07788265, step = 19757 (2.728 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07788265, step = 19757 (2.728 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3522\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 62.3522\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12929626, step = 19860 (3.970 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12929626, step = 19860 (3.970 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.1299\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 61.1299\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10345886, step = 19926 (2.747 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10345886, step = 19926 (2.747 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 20001 into s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 20001 into s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Loss for final step: 0.1622713.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Loss for final step: 0.1622713.\u001b[0m\n",
      "\u001b[35m2020-04-11 06:39:53,263 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:115: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:115: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Starting evaluation at 2020-04-11T06:39:53Z\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Starting evaluation at 2020-04-11T06:39:53Z\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt-20001\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt-20001\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished evaluation at 2020-04-11-06:39:54\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished evaluation at 2020-04-11-06:39:54\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving dict for global step 20002: accuracy = 0.9717, global_step = 20002, loss = 0.09659969\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving dict for global step 20002: accuracy = 0.9717, global_step = 20002, loss = 0.09659969\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving 'checkpoint_path' summary for global step 20002: s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt-20001\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving 'checkpoint_path' summary for global step 20002: s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt-20001\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loss for final step: 0.16082159.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loss for final step: 0.16082159.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:184: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:184: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:145: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:145: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt-20001\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-1-756783949033/tensorflow-training-2020-04-11-06-23-37-133/model/model.ckpt-20001\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/temp-b'1586587195'/saved_model.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/temp-b'1586587195'/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-04-11 06:39:57,301 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2020-04-11 06:41:11,946 sagemaker_tensorflow_container.training INFO     master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\u001b[35m2020-04-11 06:41:11,947 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[35mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[35mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[35m2020-04-11 06:41:11,947 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-11 06:42:18 Uploading - Uploading generated training model\n",
      "2020-04-11 06:42:18 Completed - Training job completed\n",
      "Training seconds: 1974\n",
      "Billable seconds: 1974\n"
     ]
    }
   ],
   "source": [
    "mnist_estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p2.xlarge for training job usage' is 1 Instances, with current utilization of 0 Instances and a request delta of 2 Instances. Please contact AWS support to request an increase for this limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-94afb6025409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist_estimator2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p2.xlarge for training job usage' is 1 Instances, with current utilization of 0 Instances and a request delta of 2 Instances. Please contact AWS support to request an increase for this limit."
     ]
    }
   ],
   "source": [
    "mnist_estimator2.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------!"
     ]
    }
   ],
   "source": [
    "predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.p3.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor2 = mnist_estimator2.deploy(initial_instance_count=1, instance_type='ml.p3.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/train_data.npy to ./train_data.npy\n",
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/train_labels.npy to ./train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_data.npy train_data.npy\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_labels.npy train_labels.npy\n",
    "\n",
    "train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 5, label is 2, matched: False\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 2, label is 2, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 5, label is 5, matched: True\n",
      "prediction is 5, label is 5, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 7, label is 7, matched: True\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]['classes']\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = predictor2.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor2.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
